{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[QUS] How_to_use_RNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Sequence를 처리하기 위한 RNN \n","\n","1. 주어진 데이터를 RNN에 넣을 수 있는 형태로 만듭니다.\n","2. 기본적인 RNN 사용법 및 적용법을 익힙니다.\n","3. LSTM, GRU의 사용법 및 적용법을 익힙니다."],"metadata":{"id":"JFC0R_4A1iU0"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"0IYwIC091UT9","executionInfo":{"status":"ok","timestamp":1640770316527,"user_tz":-540,"elapsed":5432,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"outputs":[],"source":["from tqdm import tqdm\n","from torch import nn\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","import torch"]},{"cell_type":"markdown","source":["## 데이터 전처리"],"metadata":{"id":"n8JGZ6vf3ZfT"}},{"cell_type":"markdown","source":["아래의 sample data를 확인해봅시다.  \n","전체 단어 수와 pad token의 id도 아래와 같습니다."],"metadata":{"id":"etKgmrJv3dat"}},{"cell_type":"code","source":["vocab_size = 100\n","pad_id = 0\n","\n","data = [\n","  [85,14,80,34,99,20,31,65,53,86,3,58,30,4,11,6,50,71,74,13],\n","  [62,76,79,66,32],\n","  [93,77,16,67,46,74,24,70],\n","  [19,83,88,22,57,40,75,82,4,46],\n","  [70,28,30,24,76,84,92,76,77,51,7,20,82,94,57],\n","  [58,13,40,61,88,18,92,89,8,14,61,67,49,59,45,12,47,5],\n","  [22,5,21,84,39,6,9,84,36,59,32,30,69,70,82,56,1],\n","  [94,21,79,24,3,86],\n","  [80,80,33,63,34,63],\n","  [87,32,79,65,2,96,43,80,85,20,41,52,95,50,35,96,24,80]\n","]"],"metadata":{"id":"oGR8GqPn1x9k","executionInfo":{"status":"ok","timestamp":1640770316528,"user_tz":-540,"elapsed":10,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["data[0]"],"metadata":{"id":"QMPRPFHRo1kH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640770322165,"user_tz":-540,"elapsed":4,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"e2875db0-deba-45cd-cb12-4ff7b33d5920"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[85, 14, 80, 34, 99, 20, 31, 65, 53, 86, 3, 58, 30, 4, 11, 6, 50, 71, 74, 13]"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["Padding 처리를 해주면서 padding 전 길이도 저장합니다."],"metadata":{"id":"2qPOGgoh3gYB"}},{"cell_type":"code","source":["max_len = len(max(data, key=len))\n","print(f\"Maximum sequence length: {max_len}\")\n","\n","valid_lens = []\n","for i, seq in enumerate(tqdm(data)):\n","  valid_lens.append(len(seq))\n","  if len(seq) < max_len:\n","    data[i] = seq + [pad_id] * (max_len - len(seq))"],"metadata":{"id":"l5ObMr393euW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640770327674,"user_tz":-540,"elapsed":276,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"210f87ab-d20b-40be-a0da-8ce4aaded054"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum sequence length: 20\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:00<00:00, 12365.28it/s]\n"]}]},{"cell_type":"code","source":["print(data)\n","print(valid_lens)"],"metadata":{"id":"JO9yk5KH3skJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640770338430,"user_tz":-540,"elapsed":250,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"e0d37874-7996-4e62-96e7-11c13d761c16"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[[85, 14, 80, 34, 99, 20, 31, 65, 53, 86, 3, 58, 30, 4, 11, 6, 50, 71, 74, 13], [62, 76, 79, 66, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [93, 77, 16, 67, 46, 74, 24, 70, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [19, 83, 88, 22, 57, 40, 75, 82, 4, 46, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [70, 28, 30, 24, 76, 84, 92, 76, 77, 51, 7, 20, 82, 94, 57, 0, 0, 0, 0, 0], [58, 13, 40, 61, 88, 18, 92, 89, 8, 14, 61, 67, 49, 59, 45, 12, 47, 5, 0, 0], [22, 5, 21, 84, 39, 6, 9, 84, 36, 59, 32, 30, 69, 70, 82, 56, 1, 0, 0, 0], [94, 21, 79, 24, 3, 86, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [80, 80, 33, 63, 34, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [87, 32, 79, 65, 2, 96, 43, 80, 85, 20, 41, 52, 95, 50, 35, 96, 24, 80, 0, 0]]\n","[20, 5, 8, 10, 15, 18, 17, 6, 6, 18]\n"]}]},{"cell_type":"code","source":["# B: batch size, L: maximum sequence length\n","batch = torch.LongTensor(data)  # (B, L)\n","batch_lens = torch.LongTensor(valid_lens)  # (B)"],"metadata":{"id":"ckjoQ4Hv3wi9","executionInfo":{"status":"ok","timestamp":1640770344760,"user_tz":-540,"elapsed":345,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["batch.shape"],"metadata":{"id":"FLZ0T1c233eD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640770349319,"user_tz":-540,"elapsed":2,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"f16ad357-a3f5-46ae-abea-96bedf63cbb7"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10, 20])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["batch_lens, sorted_idx = batch_lens.sort(descending=True)\n","batch = batch[sorted_idx]"],"metadata":{"id":"zT1J4yD16HLS","executionInfo":{"status":"ok","timestamp":1640770354959,"user_tz":-540,"elapsed":3,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["print(batch)\n","print(batch_lens)"],"metadata":{"id":"4m16vljl6Iem","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640770359982,"user_tz":-540,"elapsed":249,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"0444e240-24d4-4e06-9cb9-2482e57951a7"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[85, 14, 80, 34, 99, 20, 31, 65, 53, 86,  3, 58, 30,  4, 11,  6, 50, 71,\n","         74, 13],\n","        [58, 13, 40, 61, 88, 18, 92, 89,  8, 14, 61, 67, 49, 59, 45, 12, 47,  5,\n","          0,  0],\n","        [87, 32, 79, 65,  2, 96, 43, 80, 85, 20, 41, 52, 95, 50, 35, 96, 24, 80,\n","          0,  0],\n","        [22,  5, 21, 84, 39,  6,  9, 84, 36, 59, 32, 30, 69, 70, 82, 56,  1,  0,\n","          0,  0],\n","        [70, 28, 30, 24, 76, 84, 92, 76, 77, 51,  7, 20, 82, 94, 57,  0,  0,  0,\n","          0,  0],\n","        [19, 83, 88, 22, 57, 40, 75, 82,  4, 46,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0],\n","        [93, 77, 16, 67, 46, 74, 24, 70,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0],\n","        [94, 21, 79, 24,  3, 86,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0],\n","        [80, 80, 33, 63, 34, 63,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0],\n","        [62, 76, 79, 66, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0]])\n","tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"]}]},{"cell_type":"markdown","source":["## RNN 사용해보기"],"metadata":{"id":"egmXWzVx37ll"}},{"cell_type":"markdown","source":["RNN에 넣기 전 word embedding을 위한 embedding layer를 만듭니다."],"metadata":{"id":"Td9xwbbj4ABX"}},{"cell_type":"code","source":["batch.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8A2DAKR5HoKu","executionInfo":{"status":"ok","timestamp":1640770370653,"user_tz":-540,"elapsed":468,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"24618817-fa8f-43da-cd6c-0c2ec1e66342"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10, 20])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["embedding_size = 256\n","\n","## TODO ##\n","embedding = nn.Embedding(vocab_size, embedding_size)\n","\n","# d_w: embedding size\n","batch_emb = embedding(batch)  # (B, L, d_w)"],"metadata":{"id":"dbtmueDK35xw","executionInfo":{"status":"ok","timestamp":1640770382017,"user_tz":-540,"elapsed":258,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["batch.shape # [batch, token]"],"metadata":{"id":"YlSTCJCcqUeK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640770398976,"user_tz":-540,"elapsed":253,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"c0fade8c-fdcc-4963-a56d-bdb5dde691b3"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10, 20])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["batch_emb.shape # [batch(문장의 개수), token(문장의 길이), vectar(벡터의 차원)]"],"metadata":{"id":"7ccQfeYW8HTM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640770404011,"user_tz":-540,"elapsed":247,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"1bbc24ed-1334-4e44-d135-19e031e6d325"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10, 20, 256])"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["RNN 모델 및 초기 hidden state를 정의\n","\n","- batch_emb 변수를 RNN에 넣을 예정입니다.\n","- torch 공식 문서를 참조하여, RNN 모델을 정의해보세요. \n","- input size는 어떻게 되어야 하나요?"],"metadata":{"id":"PnBnduU-4GXP"}},{"cell_type":"code","source":["N, L, H_in = batch_emb.shape\n","N, L, H_in"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_VXDd-LdKHt7","executionInfo":{"status":"ok","timestamp":1640770414309,"user_tz":-540,"elapsed":235,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"2dd3b456-d468-4ba3-bac5-3a02ff72012e"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10, 20, 256)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["hidden_size = 512  # RNN의 hidden size\n","num_layers = 1  # 쌓을 RNN layer의 개수\n","num_dirs = 1  # 1: 단방향 RNN, 2: 양방향 RNN\n","\n","rnn = nn.RNN(\n","    # TODO #\n","    input_size = embedding_size,\n","    hidden_size = hidden_size,\n","    num_layers = num_layers,\n","    bidirectional = True if num_dirs > 1 else False,\n","    batch_first = False\n",")\n","\n","h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h)"],"metadata":{"id":"2RaWZKSI4Gqd","executionInfo":{"status":"ok","timestamp":1640770457718,"user_tz":-540,"elapsed":268,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["### **Vanilla RNN 활용법**"],"metadata":{"id":"Q9KD-L5YC4YH"}},{"cell_type":"markdown","source":["RNN에 batch data를 넣으면 아래와 같이 2가지 output을 얻습니다.\n","\n","\n","*   `hidden_states`: 각 time step에 해당하는 hidden state들의 묶음.\n","*   `h_n`: 모든 sequence를 거치고 나온 마지막 hidden state.\n","\n","torch의 RNN 문서를 참조하여서, ``batch_emb``변수를 rnn에 input으로 넣어보세요.\n","나온 결과의 shape도 출력해보세요. "],"metadata":{"id":"qEA7MDSl4NGw"}},{"cell_type":"code","source":["\n","# hidden_states: hidden layer\n","# h_n: final hidden layer"],"metadata":{"id":"Hov9BI27s9cA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hidden_states, h_n = rnn(batch_emb.transpose(0, 1), h_0) \n","\n","print(hidden_states.shape)\n","print(h_n.shape) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GjNqw-JMMiEh","executionInfo":{"status":"ok","timestamp":1640770491227,"user_tz":-540,"elapsed":5,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"9409bd6c-713d-49da-e1ef-17b94ba5108e"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([20, 10, 512])\n","torch.Size([1, 10, 512])\n"]}]},{"cell_type":"code","source":["hidden_states[-1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WmHZ8PvFfySf","executionInfo":{"status":"ok","timestamp":1640770496473,"user_tz":-540,"elapsed":241,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"881c7d01-e75d-42e6-a35d-088706f545d2"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.3812,  0.5036,  0.6377,  ..., -0.6816, -0.4591,  0.0435],\n","        [ 0.6007,  0.2902, -0.4161,  ...,  0.6932, -0.4274,  0.7509],\n","        [ 0.4678,  0.3690, -0.3554,  ...,  0.7706, -0.3879,  0.6034],\n","        ...,\n","        [ 0.6659,  0.3952, -0.2633,  ...,  0.7604, -0.4012,  0.5766],\n","        [ 0.6659,  0.3952, -0.2632,  ...,  0.7604, -0.4013,  0.5765],\n","        [ 0.6659,  0.3952, -0.2633,  ...,  0.7604, -0.4012,  0.5765]],\n","       grad_fn=<SelectBackward0>)"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["h_n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ya6MYnkpgFjv","executionInfo":{"status":"ok","timestamp":1640770501267,"user_tz":-540,"elapsed":312,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"0e25d123-e89b-48aa-e895-dbb59692c295"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.3812,  0.5036,  0.6377,  ..., -0.6816, -0.4591,  0.0435],\n","         [ 0.6007,  0.2902, -0.4161,  ...,  0.6932, -0.4274,  0.7509],\n","         [ 0.4678,  0.3690, -0.3554,  ...,  0.7706, -0.3879,  0.6034],\n","         ...,\n","         [ 0.6659,  0.3952, -0.2633,  ...,  0.7604, -0.4012,  0.5766],\n","         [ 0.6659,  0.3952, -0.2632,  ...,  0.7604, -0.4013,  0.5765],\n","         [ 0.6659,  0.3952, -0.2633,  ...,  0.7604, -0.4012,  0.5765]]],\n","       grad_fn=<StackBackward0>)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["hidden_states[:, -1, :], h_n.reshape(10, 1, 512)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mXCr8Vj0MWkj","executionInfo":{"status":"ok","timestamp":1640770512177,"user_tz":-540,"elapsed":311,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"0aa7658d-c536-4925-8b63-db40ee728da9"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 0.5920,  0.3999, -0.3571,  ...,  0.2564, -0.4519, -0.7771],\n","         [ 0.0773, -0.1084,  0.6425,  ..., -0.2324, -0.2264,  0.1333],\n","         [-0.0178,  0.5262, -0.0154,  ..., -0.1138,  0.4017, -0.6461],\n","         ...,\n","         [ 0.6660,  0.3953, -0.2632,  ...,  0.7604, -0.4012,  0.5765],\n","         [ 0.6660,  0.3952, -0.2633,  ...,  0.7604, -0.4013,  0.5766],\n","         [ 0.6659,  0.3952, -0.2633,  ...,  0.7604, -0.4012,  0.5765]],\n","        grad_fn=<SliceBackward0>),\n"," tensor([[[ 0.3812,  0.5036,  0.6377,  ..., -0.6816, -0.4591,  0.0435]],\n"," \n","         [[ 0.6007,  0.2902, -0.4161,  ...,  0.6932, -0.4274,  0.7509]],\n"," \n","         [[ 0.4678,  0.3690, -0.3554,  ...,  0.7706, -0.3879,  0.6034]],\n"," \n","         ...,\n"," \n","         [[ 0.6659,  0.3952, -0.2633,  ...,  0.7604, -0.4012,  0.5766]],\n"," \n","         [[ 0.6659,  0.3952, -0.2632,  ...,  0.7604, -0.4013,  0.5765]],\n"," \n","         [[ 0.6659,  0.3952, -0.2633,  ...,  0.7604, -0.4012,  0.5765]]],\n","        grad_fn=<ReshapeAliasBackward0>))"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["hidden_states.shape, h_n.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HDX9es5ELRnk","executionInfo":{"status":"ok","timestamp":1640770518177,"user_tz":-540,"elapsed":8,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"9425825c-d743-46f6-9286-e66ff6adbcaf"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([20, 10, 512]), torch.Size([1, 10, 512]))"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["마지막 hidden state를 이용하여 text classification task에 적용할 수 있습니다."],"metadata":{"id":"xOo2Xy744hT5"}},{"cell_type":"code","source":["num_classes = 2\n","classification_layer = nn.Linear(hidden_size, num_classes)\n","\n","# C: number of classes\n","output = classification_layer(h_n.squeeze(0))  # (1, B, d_h) => (B, C)\n","print(output.shape)"],"metadata":{"id":"KtdaqR0W4PdY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640770534682,"user_tz":-540,"elapsed":4,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"e7e972ed-49f1-4095-864b-f36a428c9309"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([10, 2])\n"]}]},{"cell_type":"markdown","source":["각 time step에 대한 hidden state를 이용하여 token-level의 task를 수행할 수도 있습니다."],"metadata":{"id":"K9cbRbw44kXK"}},{"cell_type":"code","source":["num_classes = 5\n","entity_layer = nn.Linear(hidden_size, num_classes)\n","\n","# C: number of classes\n","output = entity_layer(hidden_states)  # (L, B, d_h) => (L, B, C)\n","print(output.shape)"],"metadata":{"id":"yv-F7KLw4kt8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640770539102,"user_tz":-540,"elapsed":3,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"ea68eec8-9982-4847-c855-cb967496d31c"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([20, 10, 5])\n"]}]},{"cell_type":"markdown","source":["### **LSTM 활용법**"],"metadata":{"id":"inHpHVXz44T-"}},{"cell_type":"markdown","source":["LSTM에선 cell state가 추가됩니다.  \n","Cell state의 shape는 hidden state의 그것과 동일합니다.\n","\n","- batch_emb 변수를 LSTM에 넣을 예정입니다.\n","- torch 공식 문서를 참조하여, LSTM 모델을 정의해보세요. \n","- input size는 어떻게 되어야 하나요?"],"metadata":{"id":"kQGkzE7c485n"}},{"cell_type":"code","source":["hidden_size = 512\n","num_layers = 1\n","num_dirs = 1\n","\n","## TODO ##\n","lstm = nn.LSTM(\n","    input_size = embedding_size,\n","    hidden_size = hidden_size,\n","    num_layers = num_layers,\n","    bidirectional = True if num_dirs > 1 else False,\n","    batch_first = True\n",")\n","\n","h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h)\n","c_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h)"],"metadata":{"id":"VeIwgX_k45oG","executionInfo":{"status":"ok","timestamp":1640765220431,"user_tz":-540,"elapsed":536,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["torch의 LSTM 문서를 참조하여서, ``batch_emb``변수를 rnn에 input으로 넣어보세요.\n","나온 결과의 shape도 출력해보세요. "],"metadata":{"id":"-Oy7ZVdycFfS"}},{"cell_type":"code","source":["## TODO ##\n","output, (h_n, c_n) = lstm(batch_emb)"],"metadata":{"id":"-Z9E4vG65Bbx","executionInfo":{"status":"ok","timestamp":1640765248899,"user_tz":-540,"elapsed":313,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["output.shape, h_n.shape, c_n.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nofheN-EOt_F","executionInfo":{"status":"ok","timestamp":1640765272721,"user_tz":-540,"elapsed":4,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"91139e76-89b1-47f3-a3e2-e9348ebe36a6"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([10, 20, 512]), torch.Size([1, 10, 512]), torch.Size([1, 10, 512]))"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["# seq 2 seq\n","\n","#                    안 녕\n","# h1 h2 h3 h4 h5  c5 -> (lstm)\n","\n","# h e l l o"],"metadata":{"id":"CcT_5-qnO5y8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output[:, -1, :]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lnb7UrDZO1fj","executionInfo":{"status":"ok","timestamp":1640765298539,"user_tz":-540,"elapsed":276,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"outputId":"1e11ead5-9950-4ad4-bc73-9cf38980e41e"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0498, -0.0304, -0.1301,  ..., -0.1076,  0.0742, -0.0442],\n","        [-0.0247, -0.2109, -0.1264,  ..., -0.2118, -0.1255,  0.0517],\n","        [-0.0324, -0.2428, -0.0989,  ..., -0.2317, -0.0977,  0.0966],\n","        ...,\n","        [ 0.0248, -0.3107, -0.1333,  ..., -0.3804, -0.1434,  0.1037],\n","        [ 0.0238, -0.3108, -0.1335,  ..., -0.3790, -0.1432,  0.1042],\n","        [ 0.0240, -0.3110, -0.1331,  ..., -0.3797, -0.1431,  0.1037]],\n","       grad_fn=<SliceBackward0>)"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["### **GRU 사용**"],"metadata":{"id":"JcShheOD5RRG"}},{"cell_type":"markdown","source":["GRU는 cell state가 없어 RNN과 동일하게 사용 가능합니다.   \n","GRU를 이용하여 LM task를 수행해봅시다."],"metadata":{"id":"ughudT3z5TgR"}},{"cell_type":"code","source":["gru = nn.GRU(\n","    input_size=embedding_size,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    bidirectional=True if num_dirs > 1 else False\n",")"],"metadata":{"id":"hoaaK6Gn5LLK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_layer = nn.Linear(hidden_size, vocab_size)"],"metadata":{"id":"cPqE9iKP6zFX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_id = batch.transpose(0, 1)[0, :]  # (B)\n","hidden = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (1, B, d_h)"],"metadata":{"id":"VY3330vm6025"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for t in range(max_len):\n","  input_emb = embedding(input_id).unsqueeze(0)  # (1, B, d_w)\n","  output, hidden = gru(input_emb, hidden)  # output: (1, B, d_h), hidden: (1, B, d_h)\n","\n","  # V: vocab size\n","  output = output_layer(output)  # (1, B, V)\n","  probs, top_id = torch.max(output, dim=-1)  # probs: (1, B), top_id: (1, B)\n","\n","  print(\"*\" * 50)\n","  print(f\"Time step: {t}\")\n","  print(output.shape)\n","  print(probs.shape)\n","  print(top_id.shape)\n","\n","  input_id = top_id.squeeze(0)  # (B)"],"metadata":{"id":"LxKH3fqc7A_1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **양방향 및 여러 layer 사용**"],"metadata":{"id":"a6xnrQ5v7WB8"}},{"cell_type":"markdown","source":["이번엔 양방향 + 2개 이상의 layer를 쓸 때 얻을 수 있는 결과에 대해 알아봅니다.\n"],"metadata":{"id":"W6HEakT87ZvD"}},{"cell_type":"code","source":["num_layers = 2\n","num_dirs = 2\n","dropout=0.1\n","\n","gru = nn.GRU(\n","    input_size=embedding_size,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    dropout=dropout,\n","    bidirectional=True if num_dirs > 1 else False\n",")"],"metadata":{"id":"rsY16YFF7BaZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Bidirectional이 되었고 layer의 개수가 $2$로 늘었기 때문에 hidden state의 shape도 `(4, B, d_h)`가 됩니다."],"metadata":{"id":"3RBq941o7eja"}},{"cell_type":"code","source":["# d_w: word embedding size, num_layers: layer의 개수, num_dirs: 방향의 개수\n","batch_emb = embedding(batch)  # (B, L, d_w)\n","h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h) = (4, B, d_h)\n","\n","packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\n","\n","packed_outputs, h_n = gru(packed_batch, h_0)\n","print(packed_outputs)\n","print(packed_outputs[0].shape)\n","print(h_n.shape)"],"metadata":{"id":"vnX1sVRV7d6m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs, output_lens = pad_packed_sequence(packed_outputs)\n","\n","print(outputs.shape)  # (L, B, num_dirs*d_h)\n","print(output_lens)"],"metadata":{"id":"68tacMlZ7lhJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["각각의 결과물의 shape는 다음과 같습니다.\n","\n","`outputs`: `(max_len, batch_size, num_dir * hidden_size)`  \n","`h_n`: `(num_layers*num_dirs, batch_size, hidden_size)`"],"metadata":{"id":"0fEA75iy7sRK"}},{"cell_type":"code","source":["batch_size = h_n.shape[1]\n","print(h_n.view(num_layers, num_dirs, batch_size, hidden_size))\n","print(h_n.view(num_layers, num_dirs, batch_size, hidden_size).shape)"],"metadata":{"id":"BtY4oBJn7pJb"},"execution_count":null,"outputs":[]}]}