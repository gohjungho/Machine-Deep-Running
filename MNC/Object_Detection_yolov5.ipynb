{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"220117_Object_Detection_yolov5.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1V3U7MEv6YCmV1i1Y6zR0HvZfjrb_5eXG","authorship_tag":"ABX9TyOaTKNW/eelGEJzrv5Gvq7w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":[""],"metadata":{"id":"93TOCFwQXExN"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oEvgWV24qSzj","executionInfo":{"status":"ok","timestamp":1642336020440,"user_tz":-540,"elapsed":5944,"user":{"displayName":"teddy t","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08366841288043499655"}},"outputId":"2a11f5e0-05e7-4a9a-eeca-63f531239cfa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 10555, done.\u001b[K\n","remote: Total 10555 (delta 0), reused 0 (delta 0), pack-reused 10555\u001b[K\n","Receiving objects: 100% (10555/10555), 10.69 MiB | 27.78 MiB/s, done.\n","Resolving deltas: 100% (7300/7300), done.\n","\u001b[K     |████████████████████████████████| 596 kB 5.0 MB/s \n","\u001b[?25h"]}],"source":["!git clone https://github.com/ultralytics/yolov5  # clone\n","!pip install -qr yolov5/requirements.txt  # install"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","import glob\n","from datetime import datetime\n","import xml.etree.ElementTree as ET \n","import cv2\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings\n","from tqdm import tqdm\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"bEqZZh6WqaoK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Annotation Read and Handling\n","\n","- https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/"],"metadata":{"id":"v-sRAWnYqiXD"}},{"cell_type":"code","source":["!unzip \"/content/drive/MyDrive/Colab Notebooks/220117/facemask_dataset.zip\" ### todo: change the path"],"metadata":{"id":"fS1OrL7Sqgyb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_an = \"\" ### todo: change the path"],"metadata":{"id":"ePnr_B5Gqzoi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = {\n","            \"file\":[],\n","            \"name\":[],    \n","            \"width\":[],\n","            \"height\":[],\n","            \"xmin\":[],\n","            \"ymin\":[],   \n","            \"xmax\":[],\n","            \"ymax\":[],\n","           }\n","\n","for anno in tqdm(glob.glob(path_an+\"/*.xml\")):\n","    tree = ET.parse(anno)\n","    \n","    for elem in tree.iter():\n","        if 'size' in elem.tag:\n","            for attr in list(elem):\n","                if 'width' in attr.tag: \n","                    width = int(round(float(attr.text)))\n","                if 'height' in attr.tag:\n","                    height = int(round(float(attr.text)))    \n","\n","        if 'object' in elem.tag:\n","            for attr in list(elem):\n","                \n","                if 'name' in attr.tag:\n","                    name = attr.text                 \n","                    dataset['name'].append(name)\n","                    dataset['width'].append(width)\n","                    dataset['height'].append(height) \n","                    dataset['file'].append(anno.split('/')[-1][0:-4])\n","                            \n","                if 'bndbox' in attr.tag:\n","                    for dim in list(attr):\n","                        if 'xmin' in dim.tag:\n","                            xmin = int(round(float(dim.text)))\n","                            dataset['xmin'].append(xmin)\n","                        if 'ymin' in dim.tag:\n","                            ymin = int(round(float(dim.text)))\n","                            dataset['ymin'].append(ymin)                                \n","                        if 'xmax' in dim.tag:\n","                            xmax = int(round(float(dim.text)))\n","                            dataset['xmax'].append(xmax)                                \n","                        if 'ymax' in dim.tag:\n","                            ymax = int(round(float(dim.text)))\n","                            dataset['ymax'].append(ymax)\n","\n","    #break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YrIpR8LcrBDJ","executionInfo":{"status":"ok","timestamp":1642336028360,"user_tz":-540,"elapsed":433,"user":{"displayName":"teddy t","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08366841288043499655"}},"outputId":"072c2437-00cc-4574-8db9-ad4a345f5e51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 853/853 [00:00<00:00, 4238.42it/s]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"Woa0p9-FlCx_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df=pd.DataFrame(dataset)\n","\n","name_dict = {\n","    'with_mask': 0,\n","    'mask_weared_incorrect': 1,\n","    'without_mask': 2 \n","}\n","\n","df['class'] = df['name'].map(name_dict)\n","\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"4ibtQGJurJgx","executionInfo":{"status":"ok","timestamp":1642336028363,"user_tz":-540,"elapsed":28,"user":{"displayName":"teddy t","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08366841288043499655"}},"outputId":"20d6ab52-b6a3-4bc1-c194-448486badf31"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-f3a5c3c2-3f29-4ed3-8717-8459f64cdb57\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file</th>\n","      <th>name</th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>maksssksksss559</td>\n","      <td>with_mask</td>\n","      <td>400</td>\n","      <td>256</td>\n","      <td>7</td>\n","      <td>215</td>\n","      <td>50</td>\n","      <td>256</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>maksssksksss559</td>\n","      <td>with_mask</td>\n","      <td>400</td>\n","      <td>256</td>\n","      <td>64</td>\n","      <td>190</td>\n","      <td>92</td>\n","      <td>219</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>maksssksksss559</td>\n","      <td>with_mask</td>\n","      <td>400</td>\n","      <td>256</td>\n","      <td>96</td>\n","      <td>161</td>\n","      <td>148</td>\n","      <td>220</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>maksssksksss559</td>\n","      <td>with_mask</td>\n","      <td>400</td>\n","      <td>256</td>\n","      <td>183</td>\n","      <td>137</td>\n","      <td>214</td>\n","      <td>179</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>maksssksksss559</td>\n","      <td>with_mask</td>\n","      <td>400</td>\n","      <td>256</td>\n","      <td>120</td>\n","      <td>53</td>\n","      <td>138</td>\n","      <td>72</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3a5c3c2-3f29-4ed3-8717-8459f64cdb57')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f3a5c3c2-3f29-4ed3-8717-8459f64cdb57 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f3a5c3c2-3f29-4ed3-8717-8459f64cdb57');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["              file       name  width  height  xmin  ymin  xmax  ymax  class\n","0  maksssksksss559  with_mask    400     256     7   215    50   256      0\n","1  maksssksksss559  with_mask    400     256    64   190    92   219      0\n","2  maksssksksss559  with_mask    400     256    96   161   148   220      0\n","3  maksssksksss559  with_mask    400     256   183   137   214   179      0\n","4  maksssksksss559  with_mask    400     256   120    53   138    72      0"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["H, W = 640, 480\n","\n","df['xmax'] = (H/df['width'])*df['xmax']\n","df['ymax'] = (W/df['height'])*df['ymax']\n","df['xmin'] = (H/df['width'])*df['xmin']\n","df['ymin'] = (W/df['height'])*df['ymin']\n","\n","df[['xmax', 'ymax', 'xmin', 'ymin']] = df[['xmax', 'ymax', 'xmin', 'ymin']].astype('int64')\n","df['x_center'] = (df['xmax']+df['xmin'])/(2*H)\n","df['y_center'] = (df['ymax']+df['ymin'])/(2*W)\n","df['box_height'] = (df['xmax']-df['xmin'])/H\n","df['box_width'] = (df['ymax']-df['ymin'])/W\n","df['xbbox'] = df['xmax']-df['xmin']\n","df['ybbox'] = df['ymax']-df['ymin']\n","\n","sns.set()\n","sns.scatterplot(x='xbbox',  y='ybbox', data=df)\n","plt.show()"],"metadata":{"id":"4wv7FL4Oq0Xg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4UNN1yNHv-nq","executionInfo":{"status":"ok","timestamp":1642336028363,"user_tz":-540,"elapsed":24,"user":{"displayName":"teddy t","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08366841288043499655"}},"outputId":"f1e11b32-c68f-442b-d60d-808b69d2341b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 4072 entries, 0 to 4071\n","Data columns (total 9 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   file    4072 non-null   object\n"," 1   name    4072 non-null   object\n"," 2   width   4072 non-null   int64 \n"," 3   height  4072 non-null   int64 \n"," 4   xmin    4072 non-null   int64 \n"," 5   ymin    4072 non-null   int64 \n"," 6   xmax    4072 non-null   int64 \n"," 7   ymax    4072 non-null   int64 \n"," 8   class   4072 non-null   int64 \n","dtypes: int64(7), object(2)\n","memory usage: 286.4+ KB\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"XC13sxmNwOEK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Split Data into Train, Validation, and Test."],"metadata":{"id":"4277wVXYwU4E"}},{"cell_type":"code","source":["image_dir = ''\n","fileNames = [*os.listdir(image_dir)]\n","len(fileNames)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l28c-g5_wZEp","executionInfo":{"status":"ok","timestamp":1642336028366,"user_tz":-540,"elapsed":14,"user":{"displayName":"teddy t","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08366841288043499655"}},"outputId":"1e6e1462-9b28-4300-cfea-92d6bbe9602b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["853"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","train, test = train_test_split(fileNames, test_size=0.1, random_state=22)\n","test, val = train_test_split(test, test_size=0.7, random_state=22)\n","print(\"Length of Train =\",len(train))\n","print(\"=\"*30)\n","print(\"Length of Valid =\",len(val))\n","print(\"=\"*30)\n","print(\"Length of test =\", len(test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8uAKMbb-wisC","executionInfo":{"status":"ok","timestamp":1642336028857,"user_tz":-540,"elapsed":502,"user":{"displayName":"teddy t","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08366841288043499655"}},"outputId":"f8922434-5be8-40bd-b869-c4a79e72f757"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of Train = 767\n","==============================\n","Length of Valid = 61\n","==============================\n","Length of test = 25\n"]}]},{"cell_type":"code","source":["os.makedirs('./yolov5/data/train/images', exist_ok = True)\n","os.makedirs('./yolov5/data/train/labels', exist_ok = True)\n","os.makedirs('./yolov5/data/test/images', exist_ok = True)\n","os.makedirs('./yolov5/data/test/labels', exist_ok = True)\n","os.makedirs('./yolov5/data/val/images', exist_ok = True)\n","os.makedirs('./yolov5/data/val/labels', exist_ok = True)"],"metadata":{"id":"bvxsVX_Gx6Hy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","\n","def copyImages(imageList, folder_Name, height=640, width=480, from_dir='', to_dir='./yolov5/data/'):\n","    for image in tqdm(imageList):\n","        img = Image.open(os.path.join(from_dir,image))\n","        img1 = img.resize((height, width))\n","        _ = img1.save(os.path.join(to_dir,folder_Name,\"images\",image))"],"metadata":{"id":"_3sRo2MJyMRr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copyImages(train, \"train\") #### todo: set the from_dir parameter\n","copyImages(val, \"val\")  #### todo: set the from_dir parameter\n","copyImages(test, \"test\") #### todo: set the from_dir parameter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7KvwATvHydfT","executionInfo":{"status":"ok","timestamp":1642336185400,"user_tz":-540,"elapsed":156556,"user":{"displayName":"teddy t","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08366841288043499655"}},"outputId":"4fa15592-42c4-4aa1-b712-bfe67e8218f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 767/767 [02:20<00:00,  5.44it/s]\n","100%|██████████| 61/61 [00:11<00:00,  5.40it/s]\n","100%|██████████| 25/25 [00:04<00:00,  5.63it/s]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"hYN6P2uPyguq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df.astype('string')"],"metadata":{"id":"kvgcp32o0TeC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_labels(image_list, data_name, data_root = \"./yolov5/data/\"):\n","    fileNames = [x.split(\".\")[0] for x in image_list]\n","\n","    for name in tqdm(fileNames):\n","        data = df[df.file==name]\n","        box_list = []\n","        \n","        for index in range(len(data)):\n","            row = data.iloc[index]\n","            box_list.append(row['class']+\" \"+row[\"x_center\"]+\" \"+row[\"y_center\"]\\\n","                        +\" \"+row[\"box_height\"]+\" \"+row[\"box_width\"])\n","            \n","        text = \"\\n\".join(box_list)\n","        with open(os.path.join(data_root,data_name,\"labels\",name+\".txt\"), \"w\") as file:\n","            file.write(text)"],"metadata":{"id":"7vA05S4O0Vm6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["create_labels(train, \"train\")\n","create_labels(val, \"val\")\n","create_labels(test, \"test\")"],"metadata":{"id":"QigDNtAT0lsq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"YLuxEaLa0nYK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Configuration Model"],"metadata":{"id":"0f__bDsr1PMd"}},{"cell_type":"code","source":["%cd yolov5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4h-cbR-X1lSs","executionInfo":{"status":"ok","timestamp":1642336188308,"user_tz":-540,"elapsed":11,"user":{"displayName":"teddy t","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08366841288043499655"}},"outputId":"8a4a2c6b-8bc8-4cfb-feed-7ce6d935f733"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov5\n"]}]},{"cell_type":"code","source":["from IPython.core.display import Image, Video, clear_output  # to display images\n","import torch\n","from yolov5 import utils\n","display = utils.notebook_init()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5FMcFN2o1QSZ","executionInfo":{"status":"ok","timestamp":1642336194135,"user_tz":-540,"elapsed":5836,"user":{"displayName":"teddy t","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08366841288043499655"}},"outputId":"f6837806-bb11-4412-e0d0-2a69d1760afa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["YOLOv5 🚀 v6.0-192-g436ffc4 torch 1.10.0+cu111 CUDA:0 (Tesla T4, 15110MiB)\n"]},{"output_type":"stream","name":"stdout","text":["Setup complete ✅ (2 CPUs, 12.7 GB RAM, 43.2/78.2 GB disk)\n"]}]},{"cell_type":"code","source":["yaml_text = \"\"\"train: data/train/images\n","val: data/train/images\n","\n","nc: 3\n","names: ['with_mask', 'mask_weared_incorrect', 'without_mask']\"\"\""],"metadata":{"id":"VeIKYtQL1UJS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(\"data/data.yaml\", 'w') as file:\n","    file.write(yaml_text)"],"metadata":{"id":"RoFMCyyV1ts6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cat data/data.yaml\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JsCEJewh1u7y","executionInfo":{"status":"ok","timestamp":1642336194137,"user_tz":-540,"elapsed":19,"user":{"displayName":"teddy t","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08366841288043499655"}},"outputId":"d6bf489f-15c9-4782-de5f-376b3bf43580"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train: data/train/images\n","val: data/train/images\n","\n","nc: 3\n","names: ['with_mask', 'mask_weared_incorrect', 'without_mask']"]}]},{"cell_type":"code","source":["#customize iPython writefile so we can write variables\n","from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","    with open(line, 'w') as f:\n","        f.write(cell.format(**globals()))"],"metadata":{"id":"UBsM1YLX1wJq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writetemplate models/custom_yolov5s.yaml\n","\n","# parameters\n","nc: 3  # number of classes\n","depth_multiple: 0.33  # model depth multiple\n","width_multiple: 0.50  # layer channel multiple\n","\n","# anchors\n","anchors:\n","    - [10,13, 16,30, 33,23]  # P3/8\n","    - [30,61, 62,45, 59,119]  # P4/16\n","    - [116,90, 156,198, 373,326]  # P5/32\n","\n","# YOLOv5 backbone\n","backbone:\n","  # [from, number, module, args]\n","  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n","   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","   [-1, 3, BottleneckCSP, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 9, BottleneckCSP, [256]],\n","   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","   [-1, 9, BottleneckCSP, [512]],\n","   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","   [-1, 1, SPP, [1024, [5, 9, 13]]],\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n","  ]\n","\n","# YOLOv5 head\n","head:\n","    [[-1, 1, Conv, [512, 1, 1]],\n","    [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","    [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","    [-1, 3, BottleneckCSP, [512, False]],  # 13\n","\n","    [-1, 1, Conv, [256, 1, 1]],\n","    [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","    [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","    [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n","\n","    [-1, 1, Conv, [256, 3, 2]],\n","    [[-1, 14], 1, Concat, [1]],  # cat head P4\n","    [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n","\n","    [-1, 1, Conv, [512, 3, 2]],\n","    [[-1, 10], 1, Concat, [1]],  # cat head P5\n","    [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n","\n","    [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","    ]"],"metadata":{"id":"jBUfbFOZ1yNC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train yolov5s on custom data for 100 epochs\n","# time its performance\n","\n","start = datetime.now()\n","!python train.py --img 640 --batch 32 --epochs 100 --data data/data.yaml --cfg models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache\n","end = datetime.now()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7FgYOsML2HuK","executionInfo":{"status":"ok","timestamp":1642336372511,"user_tz":-540,"elapsed":177876,"user":{"displayName":"teddy t","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08366841288043499655"}},"outputId":"f3385d09-4f74-4827-a6f2-5709cefee695"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=models/custom_yolov5s.yaml, data=data/data.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=5, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5s_results, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v6.0-192-g436ffc4 torch 1.10.0+cu111 CUDA:0 (Tesla T4, 15110MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  3    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n","  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model Summary: 283 layers, 7260488 parameters, 7260488 gradients, 16.8 GFLOPs\n","\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight, 70 weight (no decay), 62 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'data/train/labels' images and labels...767 found, 0 missing, 0 empty, 0 corrupted: 100% 767/767 [00:00<00:00, 800.36it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: data/train/labels.cache\n","\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram):  17% 130/767 [00:01<00:06, 97.22it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n","\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.7GB ram): 100% 767/767 [00:08<00:00, 95.23it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/train/labels.cache' images and labels... 767 found, 0 missing, 0 empty, 0 corrupted: 100% 767/767 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.4GB ram):  52% 396/767 [00:05<00:03, 97.06it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n","\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.7GB ram): 100% 767/767 [00:09<00:00, 81.23it/s]\n","Plotting labels to runs/train/yolov5s_results/labels.jpg... \n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.66 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/yolov5s_results\u001b[0m\n","Starting training for 5 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       0/4     7.21G    0.1058   0.06618   0.03568       261       640: 100% 24/24 [00:15<00:00,  1.58it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [00:07<00:00,  1.52it/s]\n","                 all        767       3757   0.000727     0.0561    0.00046   0.000105\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       1/4     8.45G    0.1001   0.06847   0.03094       197       640: 100% 24/24 [00:11<00:00,  2.03it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [00:07<00:00,  1.58it/s]\n","                 all        767       3757   0.000749     0.0577   0.000442   0.000103\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       2/4     8.45G   0.09867   0.07139    0.0275       240       640: 100% 24/24 [00:11<00:00,  2.03it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [00:07<00:00,  1.58it/s]\n","                 all        767       3757   0.000765      0.059   0.000451   0.000105\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       3/4     8.45G   0.09734   0.06906    0.0256       198       640: 100% 24/24 [00:11<00:00,  2.03it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [00:07<00:00,  1.63it/s]\n","                 all        767       3757   0.000745     0.0574   0.000437   0.000104\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","       4/4     8.45G   0.09824   0.06866    0.0237       270       640: 100% 24/24 [00:11<00:00,  2.00it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [00:07<00:00,  1.67it/s]\n","                 all        767       3757   0.000756     0.0583   0.000446   0.000102\n","\n","5 epochs completed in 0.029 hours.\n","Optimizer stripped from runs/train/yolov5s_results/weights/last.pt, 14.9MB\n","Optimizer stripped from runs/train/yolov5s_results/weights/best.pt, 14.9MB\n","\n","Validating runs/train/yolov5s_results/weights/best.pt...\n","Fusing layers... \n","Model Summary: 232 layers, 7251912 parameters, 0 gradients, 16.8 GFLOPs\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 12/12 [00:11<00:00,  1.03it/s]\n","                 all        767       3757   0.000727     0.0561    0.00046   0.000105\n","           with_mask        767       2985    0.00218      0.168    0.00138   0.000314\n","mask_weared_incorrect        767        113          0          0          0          0\n","        without_mask        767        659          0          0          0          0\n","Results saved to \u001b[1mruns/train/yolov5s_results\u001b[0m\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"NN8DnRht2LKi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Runtime =\",end-start)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"btvkqaLn26Rb","executionInfo":{"status":"ok","timestamp":1642336374523,"user_tz":-540,"elapsed":9,"user":{"displayName":"teddy t","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08366841288043499655"}},"outputId":"4f9d840f-bc37-4c2b-f8f7-8a4bf1411f4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Runtime = 0:02:58.079036\n"]}]},{"cell_type":"code","source":["img = plt.imread('??????/train_batch0.jpg')  # todo: fill the path\n","plt.figure(figsize=(20,15))\n","plt.imshow(img)\n","plt.axis('off')\n","plt.show()"],"metadata":{"id":"3KuyMOwc26s6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"cM0pFHl328fy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation Model"],"metadata":{"id":"jywkP9I22-XV"}},{"cell_type":"code","source":["!python detect.py --source data/test/images/ --weight runs/train/yolov5s_results/weights/best.pt --name expTestImage --conf 0.4"],"metadata":{"id":"zDxM4Pux2_jS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["color_dict = {\n","    'with_mask': (0, 255, 0),\n","    'mask_weared_incorrect':  (0, 0, 255),\n","    'without_mask': (255, 0, 0) \n","}"],"metadata":{"id":"LSwlg9fj3Bka"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def show_image(img_id):\n","    df_image = df[df.file==img_id]\n","    df_image[['xmin', 'ymin', 'xmax', 'ymax']] = df_image[['xmin', 'ymin', 'xmax', 'ymax']].astype('int64')\n","    path = 'data/test/images/'+img_id+'.png'\n","    img = plt.imread(path)\n","\n","    imge = img.copy()\n","\n","    for index in range(len(df_image)):\n","        row = df_image.iloc[index]\n","        cv2.rectangle(imge, \n","                      (row['xmin'], row['ymin']),\n","                      (row['xmax'], row['ymax']),\n","                      color=color_dict[row['name']],\n","                      thickness=2)\n","\n","    img_pred = plt.imread('runs/detect/expTestImage/'+img_id+\".png\")\n","    # ===================================\n","    plt.figure(figsize=(14,17))\n","\n","    plt.subplot(1,2,1)\n","    plt.imshow(imge)\n","    plt.axis('off')\n","    plt.title('Image with Truth Box')\n","\n","    plt.subplot(1,2,2)\n","    plt.imshow(img_pred)\n","    plt.axis('off')\n","    plt.title('Image with Predicted Box')"],"metadata":{"id":"EltksqT_3DqK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["show_image(\"??????\")  # todo: set the input\n","show_image(\"?????\")  # todo: set the input\n","plt.show()"],"metadata":{"id":"FSWjVR2N3D4S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"nOrxRtAx3GQS"},"execution_count":null,"outputs":[]}]}