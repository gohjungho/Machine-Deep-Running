{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"(Student)4_fancy_rnn.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0M47aJDTXtbL"},"source":["##**4. LSTM, GRU**\n","1. 기존 RNN과 다른 부분에 대해서 배웁니다.\n","2. 이전 실습에 이어 다양한 적용법을 배웁니다."]},{"cell_type":"markdown","metadata":{"id":"jBoAWPAJSI2D"},"source":["### **필요 패키지 import**"]},{"cell_type":"code","metadata":{"id":"vEnlDHarWusL","executionInfo":{"status":"ok","timestamp":1642644837177,"user_tz":-540,"elapsed":3302,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"source":["from tqdm import tqdm\n","from torch import nn\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","import torch"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sze4MVwxSYPR"},"source":["### **데이터 전처리**"]},{"cell_type":"markdown","metadata":{"id":"ugKWDpQrSY3o"},"source":["아래의 sample data를 확인해봅시다.  \n","이전 실습과 동일합니다."]},{"cell_type":"code","metadata":{"id":"IWjwZOmGYMhw","executionInfo":{"status":"ok","timestamp":1642644837793,"user_tz":-540,"elapsed":2,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"source":["vocab_size = 100\n","pad_id = 0\n","\n","data = [\n","  [85,14,80,34,99,20,31,65,53,86,3,58,30,4,11,6,50,71,74,13],\n","  [62,76,79,66,32],\n","  [93,77,16,67,46,74,24,70],\n","  [19,83,88,22,57,40,75,82,4,46],\n","  [70,28,30,24,76,84,92,76,77,51,7,20,82,94,57],\n","  [58,13,40,61,88,18,92,89,8,14,61,67,49,59,45,12,47,5],\n","  [22,5,21,84,39,6,9,84,36,59,32,30,69,70,82,56,1],\n","  [94,21,79,24,3,86],\n","  [80,80,33,63,34,63],\n","  [87,32,79,65,2,96,43,80,85,20,41,52,95,50,35,96,24,80]\n","]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FmqlfxW_Tsfm","outputId":"0fa52d14-abf4-4831-eaa4-fae1bab6d6f1","executionInfo":{"status":"ok","timestamp":1642644842715,"user_tz":-540,"elapsed":9,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"source":["max_len = len(max(data, key=len))\n","print(f\"Maximum sequence length: {max_len}\")\n","\n","valid_lens = []\n","for i, seq in enumerate(tqdm(data)):\n","  valid_lens.append(len(seq))\n","  if len(seq) < max_len:\n","    data[i] = seq + [pad_id] * (max_len - len(seq))"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum sequence length: 20\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:00<00:00, 54755.93it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"znWCR7UbTvVE","outputId":"d1410899-849a-4a09-a608-29b056d7a265","executionInfo":{"status":"ok","timestamp":1642644844597,"user_tz":-540,"elapsed":409,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"source":["# B: batch size, L: maximum sequence length\n","batch = torch.LongTensor(data)  # (B, L)\n","batch_lens = torch.LongTensor(valid_lens)  # (B)\n","\n","batch_lens, sorted_idx = batch_lens.sort(descending=True)\n","batch = batch[sorted_idx]\n","\n","print(batch)\n","print(batch_lens)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[85, 14, 80, 34, 99, 20, 31, 65, 53, 86,  3, 58, 30,  4, 11,  6, 50, 71,\n","         74, 13],\n","        [58, 13, 40, 61, 88, 18, 92, 89,  8, 14, 61, 67, 49, 59, 45, 12, 47,  5,\n","          0,  0],\n","        [87, 32, 79, 65,  2, 96, 43, 80, 85, 20, 41, 52, 95, 50, 35, 96, 24, 80,\n","          0,  0],\n","        [22,  5, 21, 84, 39,  6,  9, 84, 36, 59, 32, 30, 69, 70, 82, 56,  1,  0,\n","          0,  0],\n","        [70, 28, 30, 24, 76, 84, 92, 76, 77, 51,  7, 20, 82, 94, 57,  0,  0,  0,\n","          0,  0],\n","        [19, 83, 88, 22, 57, 40, 75, 82,  4, 46,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0],\n","        [93, 77, 16, 67, 46, 74, 24, 70,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0],\n","        [94, 21, 79, 24,  3, 86,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0],\n","        [80, 80, 33, 63, 34, 63,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0],\n","        [62, 76, 79, 66, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0]])\n","tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"]}]},{"cell_type":"markdown","metadata":{"id":"mPRtdhHoUKhH"},"source":["### **LSTM 사용**"]},{"cell_type":"markdown","metadata":{"id":"l1FvfENCUqYN"},"source":["LSTM에선 cell state가 추가됩니다.  \n","Cell state의 shape는 hidden state의 그것과 동일합니다."]},{"cell_type":"code","metadata":{"id":"Q76VGoCCUrcQ","executionInfo":{"status":"ok","timestamp":1642645162948,"user_tz":-540,"elapsed":426,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"source":["embedding_size = 256\n","hidden_size = 512\n","num_layers = 1\n","num_dirs = 1\n","\n","embedding = nn.Embedding(vocab_size, embedding_size)\n","# ---------------------fill in ------------------------\n","lstm = nn.LSTM(\n","    input_size = embedding_size,\n","    hidden_size = hidden_size, # hidden_state와 같은 size를 가진다\n","    num_layers = num_layers,\n","    bidirectional = True if num_dirs > 1 else False\n","\n",")\n","\n","h_0 = torch.zeros(num_layers * num_dirs, batch.shape[0], hidden_size)  # (num_layers * num_dirs, B, d_h)\n","c_0 = torch.zeros(num_layers * num_dirs, batch.shape[0], hidden_size)  # (num_layers * num_dirs, B, d_h)\n","# ---------------------fill in ------------------------"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uhS7qvIKWYYb","outputId":"82795e40-50e4-4107-e4e7-9695b8aa556b","executionInfo":{"status":"ok","timestamp":1642645257334,"user_tz":-540,"elapsed":458,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"source":["# d_w: word embedding size\n","batch_emb = embedding(batch)  # (B, L, d_w)\n","\n","packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\n","\n","packed_outputs, (h_n, c_n) = lstm(packed_batch, (h_0, c_0))\n","\n","print(packed_outputs)\n","print(packed_outputs[0].shape)\n","print(h_n.shape)\n","print(c_n.shape)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["PackedSequence(data=tensor([[ 0.1824,  0.0775,  0.0523,  ...,  0.0008, -0.1086, -0.0799],\n","        [ 0.0194,  0.0365, -0.0320,  ...,  0.1192,  0.1114, -0.0124],\n","        [ 0.1333, -0.0247,  0.1339,  ..., -0.0887,  0.0798, -0.0313],\n","        ...,\n","        [-0.0979,  0.0989, -0.0329,  ..., -0.0021, -0.0887,  0.1320],\n","        [-0.1188, -0.0269,  0.0088,  ...,  0.0887,  0.0488,  0.0991],\n","        [-0.0795, -0.0683,  0.0425,  ..., -0.0937,  0.0678,  0.0728]],\n","       grad_fn=<CatBackward0>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n","         1,  1]), sorted_indices=None, unsorted_indices=None)\n","torch.Size([123, 512])\n","torch.Size([1, 10, 512])\n","torch.Size([1, 10, 512])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ArOrgjHjZqAa","outputId":"9d217212-fc47-4edb-a8b3-fe0e6050f720","executionInfo":{"status":"ok","timestamp":1642645290445,"user_tz":-540,"elapsed":398,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"source":["outputs, output_lens = pad_packed_sequence(packed_outputs)\n","print(outputs.shape)\n","print(output_lens)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([20, 10, 512])\n","tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"]}]},{"cell_type":"markdown","metadata":{"id":"meuNwIIn-H-g"},"source":["### **GRU 사용**"]},{"cell_type":"markdown","metadata":{"id":"kMUysrtLihqt"},"source":["GRU는 cell state가 없어 RNN과 동일하게 사용 가능합니다.   \n","GRU를 이용하여 LM task를 수행해봅시다."]},{"cell_type":"code","metadata":{"id":"ZHw8PSf--lVg","executionInfo":{"status":"ok","timestamp":1642645581010,"user_tz":-540,"elapsed":3400,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9c1095af-9ac5-4c77-a23a-a99718a0b0ab"},"source":["num_layers = 1\n","num_dirs = 1\n","dropout=0.1\n","\n","# ---------------------fill in ------------------------\n","gru = nn.GRU(\n","    input_size = embedding_size,\n","    hidden_size = hidden_size,\n","    num_layers = num_layers,\n","    bidirectional = True if num_dirs > 1 else False,\n","    dropout = dropout\n",")\n","# ---------------------fill in ------------------------"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]}]},{"cell_type":"code","metadata":{"id":"GbMy2CkWzobD","executionInfo":{"status":"ok","timestamp":1642645587771,"user_tz":-540,"elapsed":585,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"source":["output_layer = nn.Linear(hidden_size, vocab_size)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"YavlcFZywCBK","executionInfo":{"status":"ok","timestamp":1642645653249,"user_tz":-540,"elapsed":622,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"source":["input_id = batch.transpose(0, 1)[0, :]  # (B)\n","hidden = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (1, B, d_h)"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e1tFGyvo-uHb"},"source":["Teacher forcing 없이 이전에 얻은 결과를 다음 input으로 이용합니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J6HRC3TAxtGa","outputId":"2679ce5c-b480-4bc4-f354-9debbf11ebfb","executionInfo":{"status":"ok","timestamp":1642646574437,"user_tz":-540,"elapsed":507,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"source":["for t in range(max_len):\n","# ---------------------fill in ------------------------\n","  input_emb = embedding(input_id).unsqueeze(0) # (B, embedding_size)\n","  output, hidden = gru(input_emb, hidden) # output: (1, B, 2d_h), hidden: (1, B, d_h)\n","\n","  # V: vocab size\n","  output = output_layer(output) # (1, B, V)\n","  probs, top_id = torch.max(output, dim=-1) # use torch.max # probs: (1, B), top_id: (1, B)\n","# ---------------------fill in ------------------------\n","\n","  print(\"*\" * 50)\n","  print(f\"Time step: {t}\")\n","  print(output.shape)\n","  print(probs.shape)\n","  print(top_id.shape)\n","\n","  input_id = top_id.squeeze(0)  # (B)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["**************************************************\n","Time step: 0\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 1\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 2\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 3\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 4\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 5\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 6\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 7\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 8\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 9\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 10\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 11\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 12\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 13\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 14\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 15\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 16\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 17\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 18\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 19\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n"]}]},{"cell_type":"markdown","metadata":{"id":"WY3vh9Cm4KaH"},"source":["`max_len`만큼의 for 문을 돌면서 모든 결과물의 모양을 확인했지만 만약 종료 조건(예를 들어 문장의 끝을 나타내는 end token 등)이 되면 중간에 생성을 그만둘 수도 있습니다."]},{"cell_type":"markdown","metadata":{"id":"l07L_QncemE7"},"source":["### **양방향 및 여러 layer 사용**"]},{"cell_type":"markdown","metadata":{"id":"lasjjz-teohw"},"source":["이번엔 양방향 + 2개 이상의 layer를 쓸 때 얻을 수 있는 결과에 대해 알아봅니다."]},{"cell_type":"code","metadata":{"id":"JEy00WX3ghsb","executionInfo":{"status":"ok","timestamp":1642647349486,"user_tz":-540,"elapsed":4,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"source":["num_layers = 2\n","num_dirs = 2\n","dropout=0.1\n","\n","# ---------------------fill in ------------------------\n","gru = nn.GRU(\n","    input_size = embedding_size,\n","    hidden_size = hidden_size,\n","    num_layers = num_layers,\n","    bidirectional = True if num_dirs > 1 else False,\n","    dropout = dropout\n",")\n","# ---------------------fill in ------------------------"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QX4LVL_Ag4kK"},"source":["Bidirectional이 되었고 layer의 개수가 $2$로 늘었기 때문에 hidden state의 shape도 `(4, B, d_h)`가 됩니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q8aBk8yrfOHU","outputId":"c4dd1a5f-297c-4b6a-de6d-160dad01bfb3","executionInfo":{"status":"ok","timestamp":1642647438331,"user_tz":-540,"elapsed":443,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"source":["# d_w: word embedding size, num_layers: layer의 개수, num_dirs: 방향의 개수\n","batch_emb = embedding(batch)  # (B, L, d_w)\n","h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (num_layers * num_dirs, B, d_h) = (4, B, d_h)\n","\n","packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\n","\n","packed_outputs, h_n = gru(packed_batch, h_0)\n","print(packed_outputs)\n","print(packed_outputs[0].shape)\n","print(h_n.shape)"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["PackedSequence(data=tensor([[ 0.0086,  0.0444,  0.2085,  ..., -0.1152, -0.0325,  0.0265],\n","        [ 0.1405, -0.0113,  0.0971,  ..., -0.1391, -0.1674, -0.0039],\n","        [-0.0206,  0.1441,  0.1972,  ..., -0.2586, -0.0901, -0.1298],\n","        ...,\n","        [ 0.3757,  0.0081,  0.0317,  ..., -0.0737,  0.0219,  0.0068],\n","        [ 0.3367, -0.1520,  0.1457,  ..., -0.0227,  0.0905, -0.0835],\n","        [ 0.3294, -0.0961,  0.1549,  ...,  0.1122, -0.0427, -0.0427]],\n","       grad_fn=<CatBackward0>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n","         1,  1]), sorted_indices=None, unsorted_indices=None)\n","torch.Size([123, 1024])\n","torch.Size([4, 10, 512])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VQdVtMcehndm","outputId":"fb7b1e45-de37-4beb-d830-d07a54ab5b27","executionInfo":{"status":"ok","timestamp":1642647498926,"user_tz":-540,"elapsed":9,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"source":["outputs, output_lens = pad_packed_sequence(packed_outputs)\n","\n","print(outputs.shape)  # (L, B, num_dirs*d_h)\n","print(output_lens)"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([20, 10, 1024])\n","tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"]}]},{"cell_type":"markdown","metadata":{"id":"byuggMjekUxS"},"source":["각각의 결과물의 shape는 다음과 같습니다.\n","\n","`outputs`: `(max_len, batch_size, num_dir * hidden_size)`  \n","`h_n`: `(num_layers*num_dirs, batch_size, hidden_size)`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HaXhvyHjmFR3","outputId":"b7ff1b97-1065-45d8-9637-9a1b78f89b48","executionInfo":{"status":"ok","timestamp":1642647498927,"user_tz":-540,"elapsed":6,"user":{"displayName":"J.H. Goh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrIsNQLeNQhxpspVZqGzes7Ts8oZqO0R3WTWF_=s64","userId":"11383503404107406751"}}},"source":["batch_size = h_n.shape[1]\n","print(h_n.view(num_layers, num_dirs, batch_size, hidden_size))\n","print(h_n.view(num_layers, num_dirs, batch_size, hidden_size).shape)"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[-0.2619, -0.1103,  0.0929,  ...,  0.2554,  0.0517,  0.2495],\n","          [ 0.0665,  0.2286,  0.1908,  ..., -0.0792,  0.0275,  0.1626],\n","          [ 0.0316,  0.1185,  0.0387,  ...,  0.2256, -0.2847,  0.3328],\n","          ...,\n","          [-0.0815, -0.2650,  0.1230,  ..., -0.0883,  0.2022,  0.0359],\n","          [ 0.2881, -0.2239,  0.1764,  ...,  0.3514,  0.1189, -0.0349],\n","          [-0.1226, -0.0583, -0.3923,  ...,  0.0463,  0.3502,  0.3457]],\n","\n","         [[ 0.1995, -0.3320,  0.1185,  ...,  0.0458, -0.1279, -0.0207],\n","          [ 0.4960, -0.3557,  0.2467,  ..., -0.2606, -0.1816, -0.0065],\n","          [-0.0051, -0.3883,  0.1425,  ..., -0.2242, -0.0843, -0.1228],\n","          ...,\n","          [-0.3959,  0.2148, -0.1465,  ...,  0.1105,  0.0083, -0.1758],\n","          [ 0.0314,  0.0335,  0.3389,  ..., -0.2660, -0.3951,  0.1600],\n","          [ 0.0490, -0.0481, -0.0477,  ..., -0.3762,  0.2735, -0.1161]]],\n","\n","\n","        [[[ 0.3294, -0.0961,  0.1549,  ..., -0.0759,  0.3469,  0.1844],\n","          [-0.1412,  0.1194, -0.0361,  ..., -0.2018,  0.0640,  0.0160],\n","          [ 0.3757,  0.0081,  0.0317,  ..., -0.1507,  0.0454,  0.0229],\n","          ...,\n","          [ 0.4595, -0.1278, -0.1087,  ...,  0.0006, -0.3470,  0.0857],\n","          [ 0.0783, -0.2919, -0.0815,  ..., -0.1343,  0.0249, -0.0259],\n","          [ 0.0701,  0.1537,  0.0782,  ..., -0.3316, -0.2014,  0.2581]],\n","\n","         [[-0.1317,  0.1258, -0.2051,  ..., -0.1152, -0.0325,  0.0265],\n","          [ 0.1861, -0.1078,  0.1404,  ..., -0.1391, -0.1674, -0.0039],\n","          [ 0.0437, -0.0965,  0.3228,  ..., -0.2586, -0.0901, -0.1298],\n","          ...,\n","          [-0.1260,  0.0266,  0.0892,  ...,  0.0250, -0.1898, -0.0538],\n","          [-0.1510, -0.1476, -0.0591,  ..., -0.0630,  0.0509, -0.0419],\n","          [-0.1138, -0.0756,  0.1797,  ..., -0.1284,  0.1754, -0.2223]]]],\n","       grad_fn=<ViewBackward0>)\n","torch.Size([2, 2, 10, 512])\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"qZk_Mhp6Hx_7"},"execution_count":null,"outputs":[]}]}