{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JuNtJ7HIpq6C"
   },
   "outputs": [],
   "source": [
    "# import metrics\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "import torch # pytorch의 tensor와 그와 관련된 기본 연산 등을 지원\n",
    "import torch.nn as nn # 여러 딥러닝 layer와 loss, 함수 등을 클래스 형태로 지원\n",
    "import torch.nn.functional as F # 여러 loss, 함수 등을 function 형태로 지원\n",
    "import torch.optim as optim # 여러 optimizer를 지원\n",
    "import torchvision.models as models\n",
    "\n",
    "dev = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seE6LTW8pq6H"
   },
   "source": [
    "### CosFace\n",
    "\n",
    "![Loss function](https://drive.google.com/uc?id=15i-zpo60EgKsgvqsSljzaGhr9vzqrmd2)\n",
    "\n",
    "ArcFace와 비슷한 모델 중 하나로 CosFace라는 모델이 있습니다. 위 Loss function은 CosFace의 loss function에 해당합니다. 위 loss function을 참고하여 아래의 ??? 부분을 채워주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NFT650ihpq6H",
    "outputId": "e348b329-ffab-406d-f581-14bce54b6ac6"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "########################## 5개 ##############################\n",
    "'''\n",
    "class CosMarginProduct(nn.Module):\n",
    "    '''\n",
    "    목적 : Cosface 의 last fc layer의 구현\n",
    "    \n",
    "    인자 :\n",
    "    in_features : feature의 dimension\n",
    "    out_features : class 개수\n",
    "    '''\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.1):\n",
    "        super(CosMarginProduct, self).__init__()        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        \n",
    "        # fc의 parameter 만들기 : (in_features x out_features)의 크기를 갖는 FloatTensor로 만들 것\n",
    "        self.weight = torch.nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        '''\n",
    "        Step 1. cos(theta)-m 계산하기\n",
    "        '''\n",
    "\n",
    "        # cos_theta = (x / ||x||) * (w * ||w||) 를 이용해 cosine_theta 구하기\n",
    "        # 어느 dimension을 기준으로 normalization을 해서 torch.mm에 넘겨줘야 할까요?\n",
    "        cos = torch.mm(F.normalize(input, dim=1), F.normalize(self.weight, dim=0))\n",
    "        \n",
    "        # sin = torch.sqrt((1 - torch.pow(cosine, 2)).clamep(0, 1))\n",
    "        \n",
    "        # cos_theta - m 구하기\n",
    "        cos_m = cos - self.m\n",
    "        \n",
    "        '''\n",
    "        Step 2. cos(theta)-m 에서 dim=1에 기준으로 y_i에 해당하는 부분만 남기고 나머지는 cos(theta)로 되돌리기 \n",
    "        '''\n",
    "        one_hot = torch.zeros(cos.size()).to(dev)\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        output = (one_hot * cos_m) + ((1 - one_hot) * cos)\n",
    "        '''\n",
    "        Step 3. 최종 output 계산하기\n",
    "        '''\n",
    "        output *= self.s\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5679, -3.3301,  2.4454,  1.3051, -0.3312],\n",
       "        [ 1.4849, -2.4852, -0.1755, -0.2375, -0.7200],\n",
       "        [ 0.4409, -4.2070,  0.9451, -0.9159,  0.5482],\n",
       "        [ 1.3983, -2.0652, -1.3277, -1.3929,  0.2917],\n",
       "        [ 1.3694, -1.8475,  2.9558,  3.2490,  0.2565],\n",
       "        [-1.8637, -2.0020, -1.2830, -0.7428, -2.4385]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug = CosMarginProduct(500, 5, s=30.0, m=0.1)\n",
    "inputs = torch.randn(6, 500)\n",
    "labels = torch.ones(6)*1\n",
    "\n",
    "debug(inputs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dykwbSlnpq6L"
   },
   "source": [
    "### SphereFace\n",
    "\n",
    "![Loss function](https://drive.google.com/uc?id=1qWYN2ATdCfy8ct-Wru8lWKdy2pof-QO9)\n",
    "\n",
    "ArcFace와 비슷한 모델 중 하나로 SphereFace 모델이 있습니다. 위 Loss function은 SphereFace의 loss function에 해당합니다. 위 loss function을 참고하여 아래의 ??? 부분을 채워주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "w2bCPv5_pq6L"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "########################## 5개 ##############################\n",
    "'''\n",
    "class SphereMarginProduct(nn.Module):\n",
    "    '''\n",
    "    목적 : Sphereface의 last fc layer의 구현\n",
    "    \n",
    "    인자 :\n",
    "    in_features : feature의 dimension\n",
    "    out_features : class 개수\n",
    "    '''\n",
    "    def __init__(self, in_features, out_features, m=4):\n",
    "        super(SphereMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.m = m\n",
    "        \n",
    "        # fc의 parameter 만들기 : (out_features x in_features)의 크기를 갖는 FloatTensor로 만들 것\n",
    "        self.weight = torch.nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        '''\n",
    "        Step 1. cos(m * theta) 계산하기\n",
    "        '''\n",
    "\n",
    "        # cos_theta = (x / ||x||) * (w * ||w||) 를 이용해 cosine_theta 구하기\n",
    "        # 어느 dimension을 기준으로 normalization을 해서 F.linear에 넘겨줘야 할까요?\n",
    "        cos = F.linear(F.normalize(input, dim=1), F.normalize(self.weight, dim=1))\n",
    "        # cos(m * theta) 구하기. 논문에서 m=4로 제시하고 있으므로 m=4 일 경우에 대해서만 계산합니다.\n",
    "        # 효율성을 위해 arccos 등의 다른 연산 없이 위에서 얻은 cos만을 사용해 계산합니다.\n",
    "        # cos (2 * theta) = 2 * cos(\\theta) * cos(\\theta) - 1\n",
    "        # cos (4 * theta) = 2 * cos(2 * theta) * cos(2 * theta) = ~~~\n",
    "        cos_m = 1 - 8*(cos**2) + 8*(cos**4)\n",
    "        \n",
    "#         --> cos2 = 2*cos*cos - 1\n",
    "#         --> cos_m = 2*cos2*cos2 - 1\n",
    "        \n",
    "        '''\n",
    "        Step 2. cos(m * theta) 에서 dim=1에 기준으로 y_i에 해당하는 부분만 남기고 나머지는 cos(theta)로 되돌리기 \n",
    "        '''\n",
    "#         one_hot = torch.zeros(cos.size()).to('cpu')\n",
    "#         one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "#         output = (????? * cos_m) + (????? * cos)\n",
    "        one_hot = F.one_hot(label.long(), num_classes=self.out_features)\n",
    "        output = (one_hot * cos_m) + ((1.0 - one_hot) * cos)\n",
    "        '''\n",
    "        Step 3. 최종 output 계산하기\n",
    "        '''\n",
    "        '''\n",
    "        ##### 둘 다 맞아야 1개로 인정 #####\n",
    "        '''\n",
    "        x_norm = torch.norm(input, p='fro', dim=1) # fro: Frobenius norm\n",
    "\n",
    "        output *= x_norm.unsqueeze(dim=1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "z2J_Farbpq6O",
    "outputId": "3657d675-73e1-4010-b12a-55891bb838c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.142136\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "input = torch.ones(20, 10)\n",
    "x_norm = np.linalg.norm(input,ord=2)\n",
    "print(x_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0PCqWkEnpq6Q"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(20, 10)\n",
    "x_norm = torch.norm(x, dim=1).unsqueeze(dim=1)\n",
    "x *= x_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_aiwAbHDpq6S"
   },
   "source": [
    "### Backbone network\n",
    "\n",
    "ResNet-101을 이용하여 Backbone network를 구현합니다. 아래 코드의 ??? 부분을 채워주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "QaCDTshepq6T",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "########################## 4개 ##############################\n",
    "'''\n",
    "class FeatureNet_101(nn.Module):\n",
    "    def __init__(self, dim_feature):\n",
    "        super(FeatureNet_101, self).__init__()\n",
    "        resnet = models.resnet101(pretrained=False)\n",
    "        \n",
    "        # resnet.conv1 = nn.Conv2d(1, 64, (7,7), padding=(3,3))\n",
    "\n",
    "        # resnet-101의 마지막 Conv layer block 까지 남기고 그 뒷부분은 잘라냅니다.\n",
    "        # resnet-101 의 구조를 print해서 어디를 잘라야할 지 알 수 있습니다.\n",
    "        self.backbone = nn.Sequential(* list(resnet.children())[0:-2])\n",
    "        \n",
    "        # 마지막 Conv layer block 부분 이후로 붙는 layer들입니다.\n",
    "        # resnet-101 의 구조를 print해서 어떻게 뒤 쪽 layer를 디자인 해야할 지 알 수 있습니다.\n",
    "        self.bn_4 = nn.BatchNorm2d(2048)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc = nn.Linear(2048 * 4 * 4, dim_feature)\n",
    "        self.bn_5 = nn.BatchNorm1d(dim_feature)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        # print(out.shape) # layer 크기 구하기 \n",
    "        out = self.bn_4(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        out = self.fc(out)\n",
    "        out = self.bn_5(out)\n",
    "        return out\n",
    "    \n",
    "# debug_resnet = FeatureNet_101(512)\n",
    "# imgs = torch.randn(3, 3, 64, 64)\n",
    "# rr = debug_resnet(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KQAzSpMvpq6V",
    "outputId": "1bfc7cba-7382-4349-ce37-f6658b5da096"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2048*4*4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Km5GrMpKpq6X"
   },
   "source": [
    "### FaceNet\n",
    "\n",
    "위에서 구현한 각 모델의 마지막 FC layer들과 Backbone network를 합쳐서 하나의 얼굴인식모델을 만듭니다.\n",
    "아래 코드의 ??? 부분을 채워주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "1ZrPQkOwpq6Y"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "########################## 1개 ##############################\n",
    "'''\n",
    "class FaceNet(nn.Module):\n",
    "    '''\n",
    "    ArcMarginProduct와 FeatureNet-50 을 결합한 ArcFace 모델의 구현\n",
    "    '''\n",
    "    def __init__(self, feature_dim, cls_num, model_type='Cosface'):\n",
    "        super(FaceNet, self).__init__()\n",
    "        self.feature_net = FeatureNet_101(feature_dim)\n",
    "        \n",
    "        if model_type == 'Cosface':\n",
    "            self.classifier = CosMarginProduct(feature_dim, cls_num)\n",
    "        elif model_type == 'Sphereface':\n",
    "            self.classifier = SphereMarginProduct(feature_dim, cls_num)\n",
    "\n",
    "    # 끝까지 Forward 하여 logit을 return\n",
    "    '''\n",
    "    ##### 둘 다 맞아야 1개로 인정 #####\n",
    "    '''\n",
    "    def forward(self, x, label):\n",
    "        out = classifier(self.feature_net(x), label)\n",
    "        return out\n",
    "    \n",
    "    # Feature를 extract\n",
    "    def extract_feature(self, x):\n",
    "        out = self.feature_net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5VWCG7uYpq6a"
   },
   "outputs": [],
   "source": [
    "# 두 input 이미지의 유사도를 측정하는데 사용되는 cosine similarity\n",
    "\n",
    "def cos_dist(x1, x2):\n",
    "    return torch.sum(x1 * x2) / (torch.norm(x1) * torch.norm(x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJaZz4OWpq6c"
   },
   "source": [
    "### FaceNet\n",
    "\n",
    "FaceNet을 이용하여 두 input 사이의 similarity를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "K_7UehhUpq6c",
    "outputId": "df884cca-4461-4fa8-ff90-759cd463acaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SphereFace에서 두 input의 유사도는 0.999710 입니다.\n",
      "CosFace에서 두 input의 유사도는 0.999352216720581 입니다.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "########################## 1개 ##############################\n",
    "'''\n",
    "'''\n",
    "##### 전체 다 맞아야 하나로 인정 #####\n",
    "'''\n",
    "\n",
    "# 두 input입니다.\n",
    "x_1 = torch.randn(1, 3, 128, 128).to(dev)\n",
    "x_2 = torch.randn(1, 3, 128, 128).to(dev)\n",
    "\n",
    "# 각 model을 만듭니다. 이 모델에서 사용하는 feature의 dim은 512고 class는 총 1000개가 있습니다.\n",
    "SphereFaceNet = FaceNet(feature_dim = 512, cls_num = 1000, model_type = 'Sphereface').to(dev)\n",
    "CosFaceNet = FaceNet(feature_dim = 512, cls_num = 1000, model_type = 'Cosface').to(dev)\n",
    "\n",
    "\n",
    "# test를 위해 model을 test phase로 변경합니다.\n",
    "# 특정 layer는 training과 test 떄 다르게 동작하므로 이 설정은 필수입니다. (ex. dropout, batchnorm ...) \n",
    "\n",
    "# net.train()\n",
    "# net(tensor(1,3,256,256)) ==> 안돌아갈 시,\n",
    "# net.eval()\n",
    "# net(tensor(1,3,256,256))\n",
    "\n",
    "SphereFaceNet.eval()\n",
    "CosFaceNet.eval()\n",
    "\n",
    "\n",
    "# x_1, x_2로부터 SphereFace 모델을 이용해 feature를 추출합니다.\n",
    "feature_1 = SphereFaceNet.extract_feature(x_1)\n",
    "feature_2 = SphereFaceNet.extract_feature(x_2)\n",
    "\n",
    "# 두 feature의 유사도를 계산합니다.\n",
    "sim = cos_dist(feature_1, feature_2)\n",
    "print('SphereFace에서 두 input의 유사도는 %f 입니다.' % sim.item())\n",
    "\n",
    "# x_1, x_2로부터 CosFace 모델을 이용해 feature를 추출합니다.\n",
    "feature_1 = CosFaceNet.extract_feature(x_1)\n",
    "feature_2 = CosFaceNet.extract_feature(x_2)\n",
    "\n",
    "# 두 feature의 유사도를 계산합니다.\n",
    "sim = cos_dist(feature_1, feature_2)\n",
    "print(f'CosFace에서 두 input의 유사도는 {sim.item()} 입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Face_Recognition_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
